---
layout: post
title: "NextAI Finalist!"
date: 2017-11-19
---

Our long conference paper titled "Querying Word Embeddings for Similarity and Relatedness" has been accepted for presentation at the [NAACL 2018](http://naacl2018.org). If you have been using word embeddings without knowing the mechanism of obtaining them in an unsupervised approach using co-occurrence data, this talk will surprise you. 

Abstract: Word embeddings obtained from neural network models such as Wor2Vec Skipgram have become popular representations of word meaning and have been evaluated on a variety of word similarity and relatedness norming data. Skipgram generates a set of word and context embeddings, the latter typically discarded after training. We demonstrate the usefulness of context embeddings in predicting asymmetric association between words from a recently published dataset of production norms (Jouravlev & McRae, 2016). Our findings suggest that humans respond with words closer to the cue within the context embedding space (rather than the word embedding space), when asked to generate thematically related words.


